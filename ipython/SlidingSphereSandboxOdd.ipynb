{
 "metadata": {
  "name": "",
  "signature": "sha256:3cd2131a44a24335e1c2551dbc94066306585bdf39bf35f6aa1b372d86a3ea77"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ensure that we are in the main pdbmap directory and not a subdirectory or elsewhere\n",
      "%cd ../../pdbmap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/mikesivley/pdbmap\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load libraries\n",
      "%matplotlib inline\n",
      "import glob,gzip,os\n",
      "import numpy as np\n",
      "from numpy.random import randn\n",
      "import random\n",
      "import pandas as pd\n",
      "from scipy import stats\n",
      "from sklearn.metrics import confusion_matrix\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "pd.set_option('display.max_columns', 500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the results file into a pandas data frame\n",
      "fnames = glob.glob('/Volumes/sivleyrm/pdbmap/results/sliding_sphere_10/split/obs/bystruct/*.txt.gz')\n",
      "rlist  = [[r.split('-')[0][-4:],r.split('-')[1].split('.')[0]] for r in fnames]\n",
      "# rdf    = pd.DataFrame(rlist,columns=['structid','biounit'])\n",
      "header_fname  = 'scripts/sphere_header.txt'\n",
      "with open(header_fname,'rb') as hfin:\n",
      "    header = [h.strip() for h in hfin.readlines()]\n",
      "# Read all structures of size < 0.1MB\n",
      "sizes = [os.stat(fname).st_size/1024./1024. for fname in fnames]\n",
      "# Load every other results file, and only those < 0.1MB compressed\n",
      "dfs = [(i,pd.read_table(gzip.open(fname,'rb'),delimiter='\\t',skiprows=1,names=header)) for i,fname in enumerate(fnames) if i%2 and sizes[i]<0.1 and sizes[i]>0]\n",
      "for i,df in dfs:\n",
      "    df['structid'],df['biounit'] = [rlist[i][0] for j in range(len(df))],[rlist[i][1] for j in range(len(df))]\n",
      "# Filter out problem structures\n",
      "dfs = [df for i,df in dfs if not np.any(df.isnull().sum()==len(df))]\n",
      "df = pd.concat(dfs)\n",
      "del dfs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "CParserError",
       "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mCParserError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-43a266856056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024.\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load every other results file, and only those < 0.1MB compressed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'structid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'biounit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/mikesivley/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[1;32m    441\u001b[0m                     infer_datetime_format=infer_datetime_format)\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/mikesivley/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/mikesivley/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/mikesivley/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/mikesivley/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/mikesivley/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4629)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/mikesivley/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._get_header (pandas/parser.c:6641)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/mikesivley/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas/parser.c:7853)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/mikesivley/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas/parser.c:19604)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mCParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Spheres read:\",len(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#FIXME: This can be cleaned up by using column ranges from the header\n",
      "\n",
      "# Convenient sets of column names\n",
      "count_cols      = ['amr_snps','eas_snps','sas_snps','eur_snps','afr_snps']\n",
      "combcount_cols  = ['amr_eas_snps','amr_sas_snps','amr_eur_snps','amr_afr_snps','eas_sas_snps']\n",
      "combcount_cols += ['eas_eur_snps','eas_afr_snps','sas_eur_snps','sas_afr_snps','eur_afr_snps']\n",
      "cdaf_cols       = ['amr_cdaf','eas_cdaf','sas_cdaf','eur_cdaf','afr_cdaf']\n",
      "\n",
      "# Population comparison column names\n",
      "mean_ddaf_cols     = [\"amr_eas_meanddaf\",\"eas_amr_meanddaf\",\"amr_sas_meanddaf\",\"sas_amr_meanddaf\"]\n",
      "mean_ddaf_cols    += [\"amr_eur_meanddaf\",\"eur_amr_meanddaf\",\"amr_afr_meanddaf\",\"afr_amr_meanddaf\"]\n",
      "mean_ddaf_cols    += [\"eas_sas_meanddaf\",\"sas_eas_meanddaf\",\"eas_eur_meanddaf\",\"eur_eas_meanddaf\"]\n",
      "mean_ddaf_cols    += [\"eas_afr_meanddaf\",\"afr_eas_meanddaf\",\"sas_eur_meanddaf\",\"eur_sas_meanddaf\"]\n",
      "mean_ddaf_cols    += [\"sas_afr_meanddaf\",\"afr_sas_meanddaf\",\"eur_afr_meanddaf\",\"afr_eur_meanddaf\"]\n",
      "absmean_ddaf_cols  = [\"amreas_meanddaf\",\"amrsas_meanddaf\",\"amreur_meanddaf\",\"amrafr_meanddaf\"]\n",
      "absmean_ddaf_cols += [\"eassas_meanddaf\",\"easeur_meanddaf\",\"easafr_meanddaf\",\"saseur_meanddaf\"]\n",
      "absmean_ddaf_cols += [\"sasafr_meanddaf\",\"eurafr_meanddaf\"]\n",
      "\n",
      "# Population comparison column names (sequence windows)\n",
      "w_mean_ddaf_cols     = [\"w_amr_eas_meanddaf\",\"w_eas_amr_meanddaf\",\"w_amr_sas_meanddaf\",\"w_sas_amr_meanddaf\"]\n",
      "w_mean_ddaf_cols    += [\"w_amr_eur_meanddaf\",\"w_eur_amr_meanddaf\",\"w_amr_afr_meanddaf\",\"w_afr_amr_meanddaf\"]\n",
      "w_mean_ddaf_cols    += [\"w_eas_sas_meanddaf\",\"w_sas_eas_meanddaf\",\"w_eas_eur_meanddaf\",\"w_eur_eas_meanddaf\"]\n",
      "w_mean_ddaf_cols    += [\"w_eas_afr_meanddaf\",\"w_afr_eas_meanddaf\",\"w_sas_eur_meanddaf\",\"w_eur_sas_meanddaf\"]\n",
      "w_mean_ddaf_cols    += [\"w_sas_afr_meanddaf\",\"w_afr_sas_meanddaf\",\"w_eur_afr_meanddaf\",\"w_afr_eur_meanddaf\"]\n",
      "w_absmean_ddaf_cols  = [\"w_amreas_meanddaf\",\"w_amrsas_meanddaf\",\"w_amreur_meanddaf\",\"w_amrafr_meanddaf\"]\n",
      "w_absmean_ddaf_cols += [\"w_eassas_meanddaf\",\"w_easeur_meanddaf\",\"w_easafr_meanddaf\",\"w_saseur_meanddaf\"]\n",
      "w_absmean_ddaf_cols += [\"w_sasafr_meanddaf\",\"w_eurafr_meanddaf\"]\n",
      "\n",
      "# Convenient sets of p-value column names\n",
      "count_pval_cols      = [\"amr_snps_pval\",\"eas_snps_pval\",\"sas_snps_pval\",\"eur_snps_pval\",\"afr_snps_pval\"]\n",
      "combcount_pval_cols  = [\"amr_eas_snps_pval\",\"amr_sas_snps_pval\",\"amr_eur_snps_pval\",\"amr_afr_snps_pval\",\"eas_sas_snps_pval\"]\n",
      "combcount_pval_cols += [\"eas_eur_snps_pval\",\"eas_afr_snps_pval\",\"sas_eur_snps_pval\",\"sas_afr_snps_pval\",\"eur_afr_snps_pval\"]\n",
      "cdaf_pval_cols       = [\"amr_cdaf_pval\",\"eas_cdaf_pval\",\"sas_cdaf_pval\",\"eur_cdaf_pval\",\"afr_cdaf_pval\"]\n",
      "\n",
      "# Population comparison p-value column names\n",
      "mean_ddaf_pval_cols     = [\"amr_eas_meanddaf_pval\",\"eas_amr_meanddaf_pval\",\"amr_sas_meanddaf_pval\",\"sas_amr_meanddaf_pval\"]\n",
      "mean_ddaf_pval_cols    += [\"amr_eur_meanddaf_pval\",\"eur_amr_meanddaf_pval\",\"amr_afr_meanddaf_pval\",\"afr_amr_meanddaf_pval\"]\n",
      "mean_ddaf_pval_cols    += [\"eas_sas_meanddaf_pval\",\"sas_eas_meanddaf_pval\",\"eas_eur_meanddaf_pval\",\"eur_eas_meanddaf_pval\"]\n",
      "mean_ddaf_pval_cols    += [\"eas_afr_meanddaf_pval\",\"afr_eas_meanddaf_pval\",\"sas_eur_meanddaf_pval\",\"eur_sas_meanddaf_pval\"]\n",
      "mean_ddaf_pval_cols    += [\"sas_afr_meanddaf_pval\",\"afr_sas_meanddaf_pval\",\"eur_afr_meanddaf_pval\",\"afr_eur_meanddaf_pval\"]\n",
      "absmean_ddaf_pval_cols  = [\"amreas_meanddaf_pval\",\"amrsas_meanddaf_pval\",\"amreur_meanddaf_pval\",\"amrafr_meanddaf_pval\"]\n",
      "absmean_ddaf_pval_cols += [\"eassas_meanddaf_pval\",\"easeur_meanddaf_pval\",\"easafr_meanddaf_pval\",\"saseur_meanddaf_pval\"]\n",
      "absmean_ddaf_pval_cols += [\"sasafr_meanddaf_pval\",\"eurafr_meanddaf_pval\"]\n",
      "\n",
      "# Population comparison p-value column names (sequence windows)\n",
      "w_mean_ddaf_pval_cols     = [\"w_amr_eas_meanddaf_pval\",\"w_eas_amr_meanddaf_pval\",\"w_amr_sas_meanddaf_pval\",\"w_sas_amr_meanddaf_pval\"]\n",
      "w_mean_ddaf_pval_cols    += [\"w_amr_eur_meanddaf_pval\",\"w_eur_amr_meanddaf_pval\",\"w_amr_afr_meanddaf_pval\",\"w_afr_amr_meanddaf_pval\"]\n",
      "w_mean_ddaf_pval_cols    += [\"w_eas_sas_meanddaf_pval\",\"w_sas_eas_meanddaf_pval\",\"w_eas_eur_meanddaf_pval\",\"w_eur_eas_meanddaf_pval\"]\n",
      "w_mean_ddaf_pval_cols    += [\"w_eas_afr_meanddaf_pval\",\"w_afr_eas_meanddaf_pval\",\"w_sas_eur_meanddaf_pval\",\"w_eur_sas_meanddaf_pval\"]\n",
      "w_mean_ddaf_pval_cols    += [\"w_sas_afr_meanddaf_pval\",\"w_afr_sas_meanddaf_pval\",\"w_eur_afr_meanddaf_pval\",\"w_afr_eur_meanddaf_pval\"]\n",
      "w_absmean_ddaf_pval_cols  = [\"w_amreas_meanddaf_pval\",\"w_amrsas_meanddaf_pval\",\"w_amreur_meanddaf_pval\",\"w_amrafr_meanddaf_pval\"]\n",
      "w_absmean_ddaf_pval_cols += [\"w_eassas_meanddaf_pval\",\"w_easeur_meanddaf_pval\",\"w_easafr_meanddaf_pval\",\"w_saseur_meanddaf_pval\"]\n",
      "w_absmean_ddaf_pval_cols += [\"w_sasafr_meanddaf_pval\",\"w_eurafr_meanddaf_pval\"]\n",
      "\n",
      "# Collection of related column groups\n",
      "nest_cols      = [count_cols,combcount_cols,cdaf_cols,mean_ddaf_cols,absmean_ddaf_cols,w_mean_ddaf_cols,w_absmean_ddaf_cols]\n",
      "struct_cols      = nest_cols[:-2]\n",
      "nest_pval_cols   = [count_pval_cols,combcount_pval_cols,cdaf_pval_cols,mean_ddaf_pval_cols,absmean_ddaf_pval_cols,w_mean_ddaf_pval_cols,w_absmean_ddaf_pval_cols]\n",
      "struct_pval_cols = nest_pval_cols[:-2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Correct coding issue present in some of the results files\n",
      "# where logical 0 values were recorded as NaN, and p-values\n",
      "# were calculated from NaN instead of 0, resulting in high significance\n",
      "for col in mean_ddaf_cols+absmean_ddaf_cols+w_mean_ddaf_cols+w_absmean_ddaf_cols:\n",
      "    pcol = col+'_pval'\n",
      "    df.ix[np.isinf(df[col]),pcol] = np.nan\n",
      "    df.ix[np.isinf(df[col]),col]  = 0\n",
      "    df.ix[np.isnan(df[col]),pcol] = np.nan\n",
      "    df.ix[np.isnan(df[col]),col]  = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(df.columns)\n",
      "print df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Summary boxplots of observed values for count, cDAF, or \u0394DAF statistic, stratified by population\n",
      "for colset in nest_cols:\n",
      "    plt.figure(figsize=(15,6))\n",
      "    sns.set_style(\"whitegrid\")\n",
      "    sns.set_palette(\"hls\")\n",
      "    sns.boxplot(np.abs(df.ix[:,colset]))\n",
      "    plt.tight_layout()\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test for dDAF correlation between structural spheres and sequence windows\n",
      "for colset in nest_cols[:-2]:\n",
      "    for col in colset:\n",
      "        corr = stats.stats.pearsonr(df[col],df[\"w_%s\"%col])\n",
      "        print \"Metric: %15s;\\tCorrelation:\\t%2.3f;\\tP-Value: %.2e\"%(col,corr[0],corr[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Summary boxplots of pvalues for count, cDAF, or \u0394DAF statistic, stratified by population\n",
      "for colset in nest_pval_cols:\n",
      "    plt.figure(figsize=(15,6))\n",
      "    sns.set_style(\"whitegrid\")\n",
      "    sns.set_palette(\"hls\")\n",
      "    sns.boxplot(-np.log10(df.ix[:,colset]))\n",
      "    plt.hlines(2,0,10,'red',linestyles='dotted')\n",
      "    plt.hlines(1.3,0,10,'blue',linestyles='dotted')\n",
      "    plt.tight_layout()\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test for dDAF significance correlation between structural spheres and sequence windows\n",
      "for colset in nest_pval_cols[:-2]:\n",
      "    for col in colset:\n",
      "        corr = stats.stats.pearsonr(df[col],df[\"w_%s\"%col])\n",
      "        print \"Metric: %15s;\\tCorrelation: %2.3f;\\tP-Value: %.2e\"%(col,corr[0],corr[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate a confusion matrix using structural sphere dDAF significance \n",
      "# as the true prediction, and sequence window dDAF significance as the estimate\n",
      "import matplotlib.patheffects as PathEffects\n",
      "for colset in struct_pval_cols:\n",
      "    for col in colset:\n",
      "        fig = plt.figure(figsize=(10,10))\n",
      "        ax = fig.add_subplot(111)\n",
      "        cm = confusion_matrix(df[col]<0.05,df[\"w_%s\"%col]<0.05)\n",
      "        print cm\n",
      "        plt.text(0,0,'{0:,}'.format(cm[0][0]),fontsize=25,horizontalalignment='center',verticalalignment='center',color='white',path_effects=[PathEffects.withStroke(linewidth=3,foreground=\"black\")])\n",
      "        plt.text(0,1,'{0:,}'.format(cm[0][1]),fontsize=25,horizontalalignment='center',verticalalignment='center',color='white',path_effects=[PathEffects.withStroke(linewidth=3,foreground=\"black\")])\n",
      "        plt.text(1,0,'{0:,}'.format(cm[1][0]),fontsize=25,horizontalalignment='center',verticalalignment='center',color='white',path_effects=[PathEffects.withStroke(linewidth=3,foreground=\"black\")])\n",
      "        plt.text(1,1,'{0:,}'.format(cm[1][1]),fontsize=25,horizontalalignment='center',verticalalignment='center',color='white',path_effects=[PathEffects.withStroke(linewidth=3,foreground=\"black\")])\n",
      "        cm[0][0] = 0 # improve visualization of significant agreement/disagreement\n",
      "        # Show confusion matrix in a separate window\n",
      "        plt.imshow(cm,cmap=plt.cm.jet,interpolation='nearest')\n",
      "        plt.grid(False)\n",
      "        plt.title('dDAF Significance Confusion Matrix (%s)'%col)\n",
      "        plt.colorbar()\n",
      "        plt.ylabel('Structural dDAF Significance')\n",
      "        plt.xlabel('Sequence dDAF Significance')\n",
      "        plt.xlim([-0.5,1.5])\n",
      "        plt.ylim([-0.5,1.5])\n",
      "        plt.xticks([0,1],[\"Not Significant\",\"Significant\"])\n",
      "        plt.yticks([0,1],[\"Not Significant\",\"Significant\"])\n",
      "        plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # Boxplot for each pvalues for count, cDAF, or \u0394DAF statistic, stratified by population\n",
      "# for colset in nest_pval_cols:\n",
      "#     plt.figure(figsize=(15,6))\n",
      "#     sns.set_style(\"whitegrid\")\n",
      "#     sns.set_palette(\"hls\")\n",
      "#     sns.boxplot(-np.log10(df.ix[:,colset]))\n",
      "#     plt.hlines(2,0,10,'red',linestyles='dotted')\n",
      "#     plt.hlines(1.3,0,10,'blue',linestyles='dotted')\n",
      "#     plt.tight_layout()\n",
      "#     plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Boxplot for the number of significant spheres for count, cDAF, or \u0394DAF statistic, stratified by population, grouped protein\n",
      "for colset in nest_pval_cols:\n",
      "    ndf = []\n",
      "    plt.figure(figsize=(15,6))\n",
      "    for col in colset:\n",
      "        sns.set_style(\"whitegrid\")\n",
      "        sns.set_palette(\"hls\")\n",
      "        dfc = df[df[col]<0.05].groupby('structid').size()\n",
      "        ndf.append(dfc)\n",
      "    sns.boxplot(ndf,names=colset)\n",
      "    plt.tight_layout()\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Boxplot for significant sphere values for count, cDAF, or \u0394DAF statistic, stratified by population, grouped protein\n",
      "for i,colset in enumerate(nest_pval_cols):\n",
      "    ndf = []\n",
      "    plt.figure(figsize=(15,6))\n",
      "    for j,col in enumerate(colset):\n",
      "        sns.set_style(\"whitegrid\")\n",
      "        sns.set_palette(\"hls\")\n",
      "        dfc = df[df[col]<0.05][nest_cols[i][j]]\n",
      "        ndf.append(dfc)\n",
      "    sns.boxplot(ndf,names=nest_cols[i])\n",
      "    plt.tight_layout()\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Boxplot for mean value of significant spheres for count, cDAF, or \u0394DAF statistic, stratified by population, grouped protein\n",
      "for i,colset in enumerate(nest_pval_cols):\n",
      "    ndf = []\n",
      "    plt.figure(figsize=(15,6))\n",
      "    for j,col in enumerate(colset):\n",
      "        sns.set_style(\"whitegrid\")\n",
      "        sns.set_palette(\"hls\")\n",
      "        dfc = df[df[col]<0.05].groupby('structid')[nest_cols[i][j]].mean()\n",
      "        ndf.append(dfc)\n",
      "    sns.boxplot(ndf,names=nest_cols[i])\n",
      "    plt.tight_layout()\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot KDE histograms stratified by permutation, observed, significant (absolute mean)\n",
      "# I'll probably need to sample from the permutation set\n",
      "# I'll start with just the observed/significant values\n",
      "plt.figure(figsize=(20,6))\n",
      "sns.kdeplot(df['eurafr_meanddaf'],color='blue',label='observed')\n",
      "# sns.kdeplot(dfp['eurafr_meanddaf'],color='black',label='permutation')\n",
      "sns.kdeplot(df[df['eurafr_meanddaf_pval']<0.05]['eurafr_meanddaf'],color='red',label='significant')\n",
      "plt.xlim([-0.1,0.1])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot KDE histograms stratified by permutation, observed, significant\n",
      "# I'll probably need to sample from the permutation set\n",
      "# I'll start with just the observed/significant values\n",
      "plt.figure(figsize=(20,6))\n",
      "sns.kdeplot(df['eur_afr_meanddaf'],color='blue',label='observed',gridsize=200)\n",
      "# sns.kdeplot(dfp['eur_afr_meanddaf'],color='black',label='permutation')\n",
      "sns.kdeplot(df.ix[df['eur_afr_meanddaf_pval']<0.05,'eur_afr_meanddaf'],color='red',label='significant',gridsize=200)\n",
      "plt.xlim([-0.1,0.1])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot KDE histograms stratified by permutation, observed, significant\n",
      "# I'll probably need to sample from the permutation set\n",
      "# I'll start with just the observed/significant values\n",
      "plt.figure(figsize=(20,6))\n",
      "sns.kdeplot(df['afr_eur_meanddaf'],color='blue',label='observed')\n",
      "# sns.kdeplot(dfp['afr_eur_meanddaf'],color='black',label='permutation')\n",
      "sns.kdeplot(df[df['afr_eur_meanddaf_pval']<0.05]['afr_eur_meanddaf'],color='red',label='significant')\n",
      "plt.xlim([-0.1,0.1])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List the proteins with the *greatest number of* significant spheres for count, cDAF, and \u0394DAF, stratified by population\n",
      "for colset in nest_pval_cols:\n",
      "    ndf = []\n",
      "    for col in colset:\n",
      "        dfc = df[df[col]<0.05].groupby('structid').size()\n",
      "        dfc.sort()\n",
      "        print \"%s  %s\"%(col,' | '.join([\"%s: %.2f\"%(sid,cnt) for sid,cnt in dfc.tail(5).iteritems()][::-1]))\n",
      "    print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List the proteins with the *most extremely* significant spheres for count, cDAF, and \u0394DAF, stratified by population\n",
      "for i,colset in enumerate(nest_pval_cols):\n",
      "    ndf = []\n",
      "    for j,col in enumerate(colset):\n",
      "        dfc = df[df[col]<0.05].groupby('structid').min().sort([col,nest_cols[i][j]],ascending=[True,False]).head(5)\n",
      "        print \"%s  %s\"%(col,' | '.join([\"%s: %2.2f, p\u2264%1.1e\"%(sid,val,pval) for sid,_,pval,val in dfc.ix[:,[\"structid\",col,nest_cols[i][j]]].itertuples()]))\n",
      "    print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Top scoring 100 - Absolute\n",
      "metric = 'eurafr_meanddaf'\n",
      "pval   = 'eurafr_meanddaf_pval'\n",
      "dfc = df[df[pval]<0.05].sort([metric,'afr_snps','eur_snps'],ascending=[False,False,False])\n",
      "\n",
      "top_20_structs,i,keys = dict(),0,[]\n",
      "while len(top_20_structs) < 20:\n",
      "    sid = dfc.iloc[i].structid\n",
      "    if sid not in top_20_structs:\n",
      "        top_20_structs[sid] = 1\n",
      "        keys.append(sid)\n",
      "    else:\n",
      "        top_20_structs[sid] += 1\n",
      "    i+= 1\n",
      "# Structures ordered by the rank of their highest-ranking sphere\n",
      "# Counts are for all spheres with a higher rank than the final sphere considered\n",
      "for key in keys:\n",
      "    print key,top_20_structs[key]\n",
      "\n",
      "dfc = dfc.head(100)\n",
      "\n",
      "print \"\\n%s  %s\"%(metric,'\\n'.join([\"%s:%d.%s: %2.2f, p\u2264%1.1e afr=%d eur=%d\"%(sid,seqid,chain,val,pval,afr,eur) for _,sid,seqid,chain,pval,val,afr,eur in dfc.ix[:,[\"structid\",'seqid','chain',pval,metric,'afr_snps','eur_snps']].itertuples()]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Top scoring 100 - EUR selected\n",
      "metric = 'eur_afr_meanddaf'\n",
      "pval   = 'eur_afr_meanddaf_pval'\n",
      "dfc = df[df[pval]<0.05].sort([metric,'eur_snps','afr_snps'],ascending=[False,False,False])\n",
      "\n",
      "top_20_structs,i,keys = dict(),0,[]\n",
      "while len(top_20_structs) < 20:\n",
      "    sid = dfc.iloc[i].structid\n",
      "    if sid not in top_20_structs:\n",
      "        top_20_structs[sid] = 1\n",
      "        keys.append(sid)\n",
      "    else:\n",
      "        top_20_structs[sid] += 1\n",
      "    i+= 1\n",
      "# Structures ordered by the rank of their highest-ranking sphere\n",
      "# Counts are for all spheres with a higher rank than the final sphere considered\n",
      "for key in keys:\n",
      "    print key,top_20_structs[key]\n",
      "\n",
      "dfc = dfc.head(100)\n",
      "\n",
      "print \"\\n%s  %s\"%(metric,'\\n'.join([\"%s:%d.%s: %2.2f, p\u2264%1.1e eur=%d afr=%d\"%(sid,seqid,chain,val,pval,eur,afr) for _,sid,seqid,chain,pval,val,afr,eur in dfc.ix[:,[\"structid\",'seqid','chain',pval,metric,'afr_snps','eur_snps']].itertuples()]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Top Scoring 100 - AFR selected\n",
      "metric = 'afr_eur_meanddaf'\n",
      "pval   = 'afr_eur_meanddaf_pval'\n",
      "dfc = df[df[pval]<0.05].sort([metric,'afr_snps','eur_snps'],ascending=[False,False,False])\n",
      "\n",
      "top_20_structs,i,keys = dict(),0,[]\n",
      "while len(top_20_structs) < 20:\n",
      "    sid = dfc.iloc[i].structid\n",
      "    if sid not in top_20_structs:\n",
      "        top_20_structs[sid] = 1\n",
      "        keys.append(sid)\n",
      "    else:\n",
      "        top_20_structs[sid] += 1\n",
      "    i+= 1\n",
      "# Structures ordered by the rank of their highest-ranking sphere\n",
      "# Counts are for all spheres with a higher rank than the final sphere considered\n",
      "for key in keys:\n",
      "    print key,top_20_structs[key]\n",
      "\n",
      "dfc = dfc.head(100)\n",
      "\n",
      "print \"\\n%s  %s\"%(metric,'\\n'.join([\"%s:%d.%s: %2.2f, p\u2264%1.1e afr=%d eur=%d\"%(sid,seqid,chain,val,pval,afr,eur) for _,sid,seqid,chain,pval,val,afr,eur in dfc.ix[:,[\"structid\",'seqid','chain',pval,metric,'afr_snps','eur_snps']].itertuples()]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}