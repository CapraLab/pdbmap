{
 "metadata": {
  "name": "",
  "signature": "sha256:fbffc4fda191ed206881eaa960d71286d6df1a475cc9c2c2d1cc6fe03f0d8eec"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pymysql, pymysql.cursors\n",
      "from warnings import filterwarnings,resetwarnings\n",
      "filterwarnings('ignore', category = pymysql.Warning)\n",
      "from scipy.spatial import KDTree\n",
      "import sys,os,csv,time,math,random,copy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def connect(retry=True):\n",
      "  try:\n",
      "    con = pymysql.connect(host='gwar-dev',user='mike',passwd='cheezburger',\n",
      "                          db='pdbmap_v10',cursorclass=pymysql.cursors.Cursor)\n",
      "    return con\n",
      "  except pymysql.Error as e:\n",
      "    msg = \"There was an error connecting to the database: %s\\n\"%e\n",
      "    sys.stderr.write(msg)\n",
      "    if retry:\n",
      "      msg = \"Waiting 30-300s and retrying...\\n\"\n",
      "      sys.stderr.write(msg)\n",
      "      time.sleep(random.randint(30,300)) # Wait 30-300 seconds and retry\n",
      "      return connect(retry=False)\n",
      "    else:\n",
      "      msg = \"Database connection unsuccessful: %s\\n\"%e\n",
      "      sys.stderr.write(msg)\n",
      "      raise\n",
      "con = connect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_structure(structid,biounit,verbose=False):\n",
      "  # Load the structure\n",
      "  q  = \"SELECT e.structid,e.biounit,e.model,e.chain,a.x,a.y,a.z,e.unp,a.seqid, \"\n",
      "  q += \"(b.slabel='uniprot-pdb' and b.dlabel='1kg' and \"\n",
      "  q += \"c.label='1kg' AND c.consequence LIKE '%%missense_variant%%') as issnp, \"\n",
      "  q += \"d.name,d.aa,d.ref_allele,d.alt_allele,d.amr_af,d.asn_af,d.eur_af,d.afr_af \"\n",
      "  q += \"FROM Residue as a \"\n",
      "  q += \"INNER JOIN Chain as e ON a.label=e.label AND a.structid=e.structid \"\n",
      "  q += \"AND a.biounit=e.biounit AND a.model=e.model AND a.chain=e.chain \"\n",
      "  q += \"LEFT JOIN GenomicIntersection as b \"\n",
      "  q += \"ON a.label=b.slabel AND a.structid=b.structid \"\n",
      "  q += \"AND a.chain=b.chain AND a.seqid=b.seqid \"\n",
      "  q += \"LEFT JOIN GenomicConsequence as c \"\n",
      "  q += \"ON b.dlabel=c.label AND b.gc_id=c.gc_id \"\n",
      "  q += \"LEFT JOIN GenomicData as d \"\n",
      "  q += \"ON c.label=d.label AND c.chr=d.chr \"\n",
      "  q += \"AND c.start=d.start AND c.end=d.end AND c.name=d.name \"\n",
      "  q += \"WHERE a.label='uniprot-pdb' \"\n",
      "  q += \"AND a.structid='%s' AND a.biounit=%s \"%(structid,biounit)\n",
      "  # Place all variants at the beginning of the results\n",
      "  q += \"ORDER BY issnp DESC\"\n",
      "  global con\n",
      "  c = con.cursor() # open cursor\n",
      "  c.execute(q)\n",
      "  res = [list(r) for r in c]\n",
      "  res = sorted(res, key = lambda x: (x[7], x[8]))\n",
      "  c.close()\n",
      "  # Build a KD Tree for the residues\n",
      "  if verbose:\n",
      "    print \"  Constructing sphere matrix via KDTree...\",\n",
      "    sys.stdout.flush()\n",
      "    t0 = time.time()\n",
      "  kdt  = KDTree(np.array([r[4:7] for r in res]))\n",
      "  nbrs = dict((tuple(r[4:7]),kdt.query_ball_point(r[4:7],20)) for r in res)\n",
      "  if verbose:\n",
      "    print \"100%% (%2.2fs)\"%(time.time()-t0)\n",
      "  return res,nbrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def permute_snps(df,permutations=1000):\n",
      "    dft = copy.deepcopy(df)\n",
      "    dfres = dft.ix[:,'unp':].drop_duplicates()\n",
      "    dfsnp = dfres.ix[:,'issnp':]\n",
      "    for i in range(permutations):\n",
      "        # Permute the snp assignment indices\n",
      "        dfsnp.index = np.random.permutation(dfsnp.index)\n",
      "        # Map the new SNP assignments to each unp+seqid\n",
      "        dfres = dfres.ix[:,:'seqid'].join(dfsnp)\n",
      "        # Merge with the structural data and yield\n",
      "        yield dft.ix[:,:'seqid'].merge(dfres,on=('unp','seqid'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# And the current implementation..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_structure_current(structid,biounit,verbose=False):\n",
      "  # Load the structure\n",
      "  q  = \"SELECT !ISNULL(c.gc_id) as isvar,(b.slabel='uniprot-pdb' \"\n",
      "  q += \"and b.dlabel='1kg' and c.label='1kg' AND c.consequence LIKE \"\n",
      "  q += \"'%%missense_variant%%') as issnp,d.name,d.amr_af,d.asn_af,d.eur_af,d.afr_af,d.aa,d.ref_allele,d.alt_allele,e.structid,e.chain,e.unp,a.seqid, \"\n",
      "  q += \"a.x,a.y,a.z FROM Residue as a \"\n",
      "  q += \"INNER JOIN Chain as e ON a.label=e.label AND a.structid=e.structid \"\n",
      "  q += \"AND a.biounit=e.biounit AND a.model=e.model AND a.chain=e.chain \"\n",
      "  q += \"LEFT JOIN GenomicIntersection as b \"\n",
      "  q += \"ON a.label=b.slabel AND a.structid=b.structid \"\n",
      "  q += \"AND a.chain=b.chain AND a.seqid=b.seqid \"\n",
      "  q += \"LEFT JOIN GenomicConsequence as c \"\n",
      "  q += \"ON b.dlabel=c.label AND b.gc_id=c.gc_id \"\n",
      "  q += \"LEFT JOIN GenomicData as d \"\n",
      "  q += \"ON c.label=d.label AND c.chr=d.chr \"\n",
      "  q += \"AND c.start=d.start AND c.end=d.end AND c.name=d.name \"\n",
      "  q += \"WHERE a.label='uniprot-pdb' \"\n",
      "  q += \"AND a.structid='%s' AND a.biounit=%s \"%(structid,biounit)\n",
      "  # Place all variants at the beginning of the results\n",
      "  q += \"ORDER BY issnp DESC\"\n",
      "  global con\n",
      "  c = con.cursor() # open cursor\n",
      "  c.execute(q)\n",
      "  res = [list(r) for r in c]\n",
      "  c.close()\n",
      "  # Build a KD Tree for the residues\n",
      "  if verbose:\n",
      "    print \"Constructing sphere matrix via KDTree...\",\n",
      "    sys.stdout.flush()\n",
      "    t0 = time.time()\n",
      "  kdt  = KDTree(np.array([r[-3:] for r in res]))\n",
      "  nbrs = dict((tuple(r[-3:]),kdt.query_ball_point(r[-3:],20)) for r in res)\n",
      "  if verbose:\n",
      "    print \"100%% (%2.2fs)\"%(time.time()-t0)\n",
      "  return res,nbrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def permute_snps_current(residues,permutations=1000):\n",
      "  locseen = set() # Track unique locations\n",
      "  snpseen = set() # Track unqiue SNPs\n",
      "  locseen_add,snpseen_add = locseen.add,snpseen.add\n",
      "  loc_mat = []    # Matrix of variant coordinates (3D)\n",
      "  snps    = []    # List of missense SNPs\n",
      "  mafs    = []    # List of minor allele frequencies. Order matches snps\n",
      "  snpidx  = []    # (unp,seqid) for each variant in this structure\n",
      "  residx  = {}    # (unp,seqid)->[residue-index] for each residue in loc_mat\n",
      "  for r in residues:\n",
      "    r = tuple(r)\n",
      "    if not (tuple(r[-3:]) in locseen or locseen_add(tuple(r[-3:]))):\n",
      "      loc_mat.append(r[-3:])\n",
      "      # Assign this structural location index to a unique sequence residue\n",
      "      if r[-5:-3] not in residx:\n",
      "        residx[r[-5:-3]] = []\n",
      "      residx[r[-5:-3]].append(len(loc_mat)-1)\n",
      "      # Check if the location is a variant residue\n",
      "      if r[1]:\n",
      "        # Check if a variant has already been mapped to this residue\n",
      "        if not (tuple(r[-5:-3]) in snpseen or snpseen_add(tuple(r[-5:-3]))):\n",
      "          # snps.append(r[2])\n",
      "          mafs.append(r[2:10]) # all allele information\n",
      "          # Assign this variant to the unique sequence residue\n",
      "          snpidx.append(r[-5:-3])\n",
      "  # Reduce the location matrix to unique residues (remove multi-variant mappings)\n",
      "  loc_mat  = [list(x) for x in loc_mat]\n",
      "  rescount = len(loc_mat) # Number of residues\n",
      "  snpres   = len([r for v in snpidx for r in residx[v]]) # Number of residues mapped to variants\n",
      "  snpcount = len(snpidx) # Number of variants\n",
      "  perm_residues = copy.deepcopy(residues)\n",
      "  for i in range(permutations):\n",
      "    # Reset SNP assignments\n",
      "    for r in perm_residues:\n",
      "      r[1] = 0\n",
      "      r[2:10] = [None,0,0,0,0,None,None,None]\n",
      "    # Permute the snpidx assignments, propagate through residx to loc_mat\n",
      "    # More accurately models plausible variant distribution\n",
      "    perm_snpidx   = random.sample(residx.keys(),snpcount)\n",
      "    resseen     = set()\n",
      "    resseen_add = resseen.add\n",
      "    for r in perm_residues:\n",
      "      if tuple(r[-5:-3]) in perm_snpidx:\n",
      "        r[1] = 1\n",
      "        resseen_add(tuple(r[-5:-3]))\n",
      "        r[2:10] = list(mafs[list(resseen).index(tuple(r[-5:-3]))])\n",
      "    yield perm_residues"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing the old way\n",
      "res1,nbrs1 = load_structure_current('1pl8',1,verbose=True)\n",
      "t0 = time.time()\n",
      "_ = [x for x in permute_snps_current(res1,1000)]\n",
      "print \"1000 permutations required %2.2fs\"%(time.time()-t0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Constructing sphere matrix via KDTree..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100% (16.58s)\n",
        "1000 permutations required 2.21s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# and the new way\n",
      "res,nbrs = load_structure('1pl8',1,verbose=True)\n",
      "t0 = time.time()\n",
      "# Convert to pandas dataframe and group by unp.seqid\n",
      "colnames  = ['structid','biounit','model','chain','x','y','z','unp','seqid']\n",
      "colnames += ['issnp','name','aa','ref','alt','amr_af','asn_af','eur_af','afr_af']\n",
      "df = pd.DataFrame(res,columns=colnames)\n",
      "_ = [x for x in permute_snps(df,1000)]\n",
      "print \"1000 permutations required %2.2fs\"%(time.time()-t0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Constructing sphere matrix via KDTree..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100% (16.50s)\n",
        "1000 permutations required 5.88s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# And now the newest way!\n",
      "# Don't mind the syntax errors, its an indentation problem\n",
      "# caused by copying this code around between systems. I'll\n",
      "# need to integrate this into the main codebase anyway.\n",
      "# Performs 10k permutations in 5s.\n",
      "\n",
      "query = \"\"\"\n",
      "SELECT\n",
      "/*SLABEL*/a.label as slabel,\n",
      "/*ID*/a.structid,\n",
      "/*METHOD*/IF(c.method IS NULL,d.method,c.method) as method,\n",
      "/*STRUCTURE*/c.resolution,\n",
      "/*MODEL*/d.mpqs,\n",
      "/*CHAIN*/b.biounit,b.model,b.chain,b.unp,b.hybrid,\n",
      "/*RESIDUE*/a.seqid as seqid,a.icode,a.rescode,a.ss,a.phi,a.psi,a.tco,a.kappa,a.alpha,a.x,a.y,a.z,\n",
      "/*PFAM*/p.acc as pfamid,p.name as pfam_domain,p.description as pfam_desc,p.evalue as pfam_evalue,\n",
      "/*ALIGN*/h.chain_seqid as aln_chain_seqid,h.trans_seqid as aln_trans_seqid,j.perc_identity,\n",
      "/*TRANS*/i.transcript as enst,i.gene as ensg,i.protein as ens_prot,i.seqid as ens_prot_seqid,i.rescode as ens_prot_aa,\n",
      "/*DLABEL*/g.label as dlabel,\n",
      "/*VARIANT*/(e.slabel='uniprot-pdb' and e.dlabel='1kg' and f.label='1kg' AND f.consequence LIKE '%%missense_variant%%') as issnp,\n",
      "/*VARIANT*/g.name as snpid,g.chr,g.start,g.end,g.hgnc_gene,g.ens_gene,g.aa as anc_allele,g.ref_allele,g.alt_allele,g.maf,g.amr_af,g.asn_af,g.eur_af,g.afr_af,\n",
      "/*CONSEQUENCE*/f.gc_id,f.transcript as vep_trans,f.protein as vep_prot,f.protein_pos as vep_prot_pos,f.ref_codon,f.alt_codon,f.ref_amino_acid as vep_ref_aa,f.alt_amino_acid as vep_alt_aa,\n",
      "/*CONSEQUENCE*/f.consequence,f.polyphen,f.sift,f.biotype\n",
      "FROM Residue as a\n",
      "LEFT JOIN Chain as b\n",
      "ON a.label=b.label AND a.structid=b.structid AND a.biounit=b.biounit AND a.model=b.model AND a.chain=b.chain\n",
      "LEFT JOIN Structure as c\n",
      "ON b.label=c.label AND b.structid=c.pdbid\n",
      "LEFT JOIN Model as d\n",
      "ON b.label=d.label AND b.structid=d.modelid\n",
      "LEFT JOIN GenomicIntersection as e\n",
      "ON a.label=e.slabel AND a.structid=e.structid AND a.chain=e.chain AND a.seqid=e.seqid\n",
      "LEFT JOIN GenomicConsequence as f\n",
      "ON e.dlabel=f.label AND e.gc_id=f.gc_id\n",
      "LEFT JOIN GenomicData as g\n",
      "ON f.label=g.label AND f.chr=g.chr AND f.start=g.start AND f.end=g.end AND f.name=g.name\n",
      "LEFT JOIN Alignment as h USE INDEX(PRIMARY)\n",
      "ON a.label=h.label AND a.structid=h.structid AND a.chain=h.chain AND a.seqid=h.chain_seqid #AND f.transcript=h.transcript\n",
      "LEFT JOIN Transcript as i USE INDEX(PRIMARY)\n",
      "ON h.label=i.label AND h.transcript=i.transcript AND h.trans_seqid=i.seqid\n",
      "LEFT JOIN AlignmentScore as j\n",
      "ON h.label=j.label AND h.structid=j.structid AND h.chain=j.chain AND h.transcript=j.transcript\n",
      "LEFT JOIN pfam as p\n",
      "ON a.structid=p.pdbid AND a.chain=p.chain AND a.seqid BETWEEN p.seqstart AND p.seqend\n",
      "WHERE a.label='uniprot-pdb'\n",
      "AND b.label='uniprot-pdb'\n",
      "AND (g.label IS NULL OR g.label='1kg')\n",
      "AND (f.transcript IS NULL OR f.transcript=h.transcript)\n",
      "AND (c.method LIKE '%%nmr%%' OR b.biounit>0 OR NOT ISNULL(d.modelid))\n",
      "AND a.structid=%s AND a.biounit=%s\n",
      "ORDER BY b.unp,a.seqid DESC;\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_structure(structid,biounit=0):\n",
      "\u00a0 global query\n",
      "\u00a0 q = secure_query(query,qvars=(structid,biounit),cursorclass='DictCursor')\n",
      "\u00a0 # Construct the Bio.PDB.Structure\n",
      "\u00a0 s = None\n",
      "\u00a0 for row in q:\n",
      "\u00a0\u00a0\u00a0 if not s:\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 s = Bio.PDB.Structure.Structure(row['structid'])\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 s.biounit\u00a0\u00a0\u00a0 = row['biounit']\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 s.resolution = row['resolution'] if row['resolution'] else None\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 s.mpqs\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 = row['mpqs'] if row['mpqs'] else None\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 s.method\u00a0\u00a0\u00a0\u00a0 = row['method']\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 s.snpmapper\u00a0 = {}\n",
      "\u00a0\u00a0\u00a0 m = row['model']\n",
      "\u00a0\u00a0\u00a0 if m not in s: s.add(Bio.PDB.Model.Model(m))\n",
      "\u00a0\u00a0\u00a0 m = s[m]\n",
      "\u00a0\u00a0\u00a0 c = row['chain']\n",
      "\u00a0\u00a0\u00a0 if c not in m: m.add(Bio.PDB.Chain.Chain(c))\n",
      "\u00a0\u00a0\u00a0 c = m[c]\n",
      "\u00a0\u00a0\u00a0 c.unp\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 = row['unp']\n",
      "\u00a0\u00a0\u00a0 c.transcript\u00a0 = row['enst']\n",
      "\u00a0\u00a0\u00a0 c.gene\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 = row['ensg']\n",
      "\u00a0\u00a0\u00a0 c.perc_identity = row['perc_identity']\n",
      "\u00a0\u00a0\u00a0 c.hybrid\u00a0 = row['hybrid']\n",
      "\u00a0\u00a0\u00a0 r = (' ',row['seqid'], ' ')\n",
      "\u00a0\u00a0\u00a0 c.add(Bio.PDB.Residue.Residue(r,row['rescode'],' '))\n",
      "\u00a0\u00a0\u00a0 r = c[r]\n",
      "\u00a0\u00a0\u00a0 r.seqid = row['seqid']\n",
      "\u00a0\u00a0\u00a0 r.coords = (row['x'],row['y'],row['z'])\n",
      "\u00a0\u00a0\u00a0 r.pfam\u00a0\u00a0 = (row['pfamid'],row['pfam_domain'],row['pfam_desc'],row['pfam_evalue'])\n",
      "\u00a0\u00a0\u00a0 r.ss\u00a0\u00a0\u00a0\u00a0 = row['ss']\n",
      "\u00a0\u00a0\u00a0 r.angles = (row['phi'],row['psi'],row['tco'],row['kappa'],row['alpha'])\n",
      "\u00a0\u00a0\u00a0 if c.unp not in s.snpmapper:\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 s.snpmapper[c.unp] = np.array([[None for j in range(19)] for i in range(r.seqid)])\n",
      "\u00a0\u00a0\u00a0 if not np.any(s.snpmapper[c.unp][r.seqid-1]):\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 snp\u00a0 = [row['issnp'],row['snpid'],row['chr'],row['start'],row['end'],row['hgnc_gene'],row['ens_gene']]\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 snp += [row['anc_allele'],row['ref_allele'],row['alt_allele']]\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 snp += [row['maf'],row['amr_af'],row['asn_af'],row['eur_af'],row['afr_af']]\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 snp += [row['ref_codon'],row['alt_codon'],row['vep_ref_aa'],row['vep_alt_aa']]\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 s.snpmapper[c.unp][r.seqid-1] = snp\n",
      "\u00a0\u00a0\u00a0 r.snp = s.snpmapper[c.unp][r.seqid-1]\n",
      "\u00a0 return s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def permute(ts,n=10):\n",
      "\u00a0\u00a0\u00a0 ts = copy.deepcopy(s.snpmapper)\n",
      "\u00a0\u00a0\u00a0 for i in range(n):\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 for unp in s.snpmapper.keys():\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 np.random.shuffle(s.snpmapper[unp])\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 yield s\n",
      "\u00a0\u00a0\u00a0 s.snpmapper = ts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}